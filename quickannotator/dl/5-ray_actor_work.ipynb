{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install ray[train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U ipywidgets\n",
    "# not needed for production, only for jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- should clean imports - copy paste\n",
    "import ray\n",
    "from ray.train import ScalingConfig\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from torchvision.datasets import FashionMNIST\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "import ray.train.torch\n",
    "import ray.util.state\n",
    "import ray\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import ray.train.torch\n",
    "import ray.train\n",
    "from torch.nn import CrossEntropyLoss, MSELoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickannotator.dl.training import train_model\n",
    "\n",
    "#@ray.remote\n",
    "class DLActor:\n",
    "    def __init__(self,classid,status=-1):\n",
    "        self.classid=classid\n",
    "        self.status=status\n",
    "        \n",
    "    def start_dlproc(self,is_train=True,allow_pred=True):\n",
    "        #need to check if is already training, if yes, no opt\n",
    "        print(\"starting up\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        #scaling_config = ray.train.ScalingConfig(num_workers=2, use_gpu=True,resources_per_worker={\"GPU\":.5})\n",
    "        ## will fail on single node single gpu --- (DLActor pid=174521) Duplicate GPU detected : rank 1 and rank 0 both on CUDA device 1000\n",
    "\n",
    "        #--- NEED A GPU CONTAINER TO TEST THIS        \n",
    "        # total_gpus  = ray.cluster_resources().get(\"GPU\", 0)\n",
    "        # total_gpus_available=  ray.available_resources().get(\"GPU\", 0)\n",
    "        # print(total_gpus,total_gpus_available)\n",
    "        # resource_to_request = (total_gpus_available/total_gpus)/2 * 1.01\n",
    "        # print(f\"resource_to_request: {resource_to_request}\")\n",
    "\n",
    "        # scaling_config = ray.train.ScalingConfig(num_workers=total_gpus, use_gpu=True, resources_per_worker={\"GPU\":resource_to_request})\n",
    "        \n",
    "\n",
    "        #----\n",
    "        scaling_config = ray.train.ScalingConfig(num_workers=1, use_gpu=False)\n",
    "        trainer = ray.train.torch.TorchTrainer(train_model,\n",
    "                                       scaling_config=scaling_config,\n",
    "                                       train_loop_config={'is_train':is_train, \n",
    "                                                          'allow_pred':allow_pred,\n",
    "                                                         'classid':self.classid})\n",
    "        self.status = trainer.fit().hex() ##widly -- this doesn't save the result in the actor\n",
    "        return self.status\n",
    "    \n",
    "    # def infer(self,tileid):\n",
    "    #     import datetime\n",
    "    #     #go into seen database, set tileid equal to true, and set date\n",
    "    #     Seen,session = setupdb()\n",
    "        \n",
    "\n",
    "    #     row_to_update = session.query(Seen).filter(Seen.tileid == tileid,\n",
    "    #                                                Seen.classid==self.classid).first()\n",
    "\n",
    "    #     if row_to_update:\n",
    "            \n",
    "    #         row_to_update.date = datetime.datetime.now()\n",
    "    #         row_to_update.status = 1\n",
    "\n",
    "    #         # Commit the changes\n",
    "    #         session.commit()\n",
    "    #         print(f\"Updated tileid {tileid}: status set to 1 and date updated.\")\n",
    "    #     else:\n",
    "    #         print(f\"No entry found for tileid {tileid}.\")\n",
    "\n",
    "    #     session.close()\n",
    "\n",
    "    #     #if start_dlproc not running, then need to start it, but set it to no train, just pred --- start_dlproc(is_train=False)\n",
    "        \n",
    "    #     return tileid\n",
    "        \n",
    "        \n",
    "\n",
    "    # def bulkinfer(self,tileids):\n",
    "    #     import sqlalchemy, datetime\n",
    "    #     Seen,session = setupdb()\n",
    "        \n",
    "\n",
    "    #     stmt = (sqlalchemy.update(Seen).where(Seen.tileid.in_(tileids),\n",
    "    #                                           Seen.classid==self.classid).values(status=1,date=datetime.datetime.now()))\n",
    "\n",
    "    #     # Execute the update\n",
    "    #     session.execute(stmt)\n",
    "    #     session.commit()\n",
    "        \n",
    "    #     # Close the session\n",
    "    #     session.close()\n",
    "\n",
    "\n",
    "    #     #need a similar statement to get the DL starting\n",
    "    #     return True\n",
    "        \n",
    "    def getclassid(self):\n",
    "        return self.classid\n",
    "        \n",
    "    \n",
    "    def getstatus(self):\n",
    "        print(\"in get status!\")\n",
    "        print(f\"self.status:\\t {self.status}\")\n",
    "        return self.status\n",
    "\n",
    "    def setstatus(self,status):\n",
    "        self.status=status\n",
    "        return self.status\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2=DLActor(classid=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2.start_dlproc(is_train=True,allow_pred=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class2 = DLActor.options(max_concurrency=2).remote(classid=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ray.get(class2.getclassid.remote()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref2=class2.start_dlproc.remote()\n",
    "print(ref2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickannotator.dl.training import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quickannotator.db import db, Project, Image, AnnotationClass, Notification, Tile, Setting, Annotation, SearchCache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- need to run \n",
    "#memcached -m 10240 -I 20m -vv -u www-data &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/QuickAnnotator/quickannotator/dl/training.py:26: UserWarning: Argument 'eps' is not valid and will be ignored.\n",
      "  A.RandomGamma(p=.5, gamma_limit=(80, 120), eps=1e-07),\n",
      "InitSpatiaMetaData() error:\"table spatial_ref_sys already exists\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(self.tiles)=5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]InitSpatiaMetaData() error:\"table spatial_ref_sys already exists\"\n",
      "InitSpatiaMetaData() error:\"table spatial_ref_sys already exists\"\n",
      "3it [00:42, 14.26s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclassid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtile_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2_048\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/QuickAnnotator/quickannotator/dl/training.py:74\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     72\u001b[0m unlabeled_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.1\u001b[39m \u001b[38;5;241m*\u001b[39m (loss \u001b[38;5;241m*\u001b[39m unlabeled_mask)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     73\u001b[0m loss_total \u001b[38;5;241m=\u001b[39m positive_loss \u001b[38;5;241m+\u001b[39m unlabeled_loss\n\u001b[0;32m---> 74\u001b[0m \u001b[43mloss_total\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     76\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss_total\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/QuickAnnotator/venv/lib/python3.8/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/QuickAnnotator/venv/lib/python3.8/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/QuickAnnotator/venv/lib/python3.8/site-packages/torch/autograd/graph.py:769\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    768\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    770\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    772\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    773\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model({\"classid\":2,\"tile_size\":2_048})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
