{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:35:07.546312Z",
     "start_time": "2024-11-08T14:35:06.944945Z"
    }
   },
   "source": [
    "from geoalchemy2 import Geometry, load_spatialite\n",
    "from flask_caching import Cache\n",
    "from sqlalchemy import event, Table, insert, func, select, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "import os\n",
    "from flask import Flask\n",
    "from quickannotator.db import Project, Image, AnnotationClass, Notification, Tile, Setting, Annotation\n",
    "from quickannotator.db import db\n",
    "import large_image\n",
    "import math\n",
    "import numpy as np \n",
    "from shapely.geometry import Point, Polygon, LineString, MultiLineString, MultiPolygon\n",
    "import random\n",
    "from shapely.affinity import translate\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import shapely\n",
    "from shapely.geometry import shape\n",
    "from api.v1.tile.helper import tiles_within_bbox\n",
    "from api.v1.annotation.helper import count_annotations_within_bbox\n",
    "import geojson"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "bca4dff6768ff12f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:35:07.555966Z",
     "start_time": "2024-11-08T14:35:07.549569Z"
    }
   },
   "source": [
    "app = Flask(\"app\")\n",
    "SearchCache = Cache(config={'CACHE_TYPE': 'SimpleCache'})\n",
    "SearchCache.init_app(app)\n",
    "app.config['SQLALCHEMY_DATABASE_URI'] = 'sqlite:///quickannotator.db'\n",
    "os.environ['SPATIALITE_LIBRARY_PATH'] = '/usr/lib/x86_64-linux-gnu/mod_spatialite.so'\n",
    "\n",
    "db.app = app\n",
    "db.init_app(app)\n",
    "\n",
    "\n",
    "with app.app_context():\n",
    "    db.engine.echo = False\n",
    "    event.listen(db.engine, 'connect', load_spatialite)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "209fd4ac277bf06c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:35:07.616656Z",
     "start_time": "2024-11-08T14:35:07.602332Z"
    }
   },
   "source": [
    "def insert_project(app, db, name, description, is_dataset_large):\n",
    "    with app.app_context():\n",
    "        project = Project(name=name,\n",
    "                          description=description,\n",
    "                          is_dataset_large=is_dataset_large)\n",
    "        db.session.add(project)\n",
    "        db.session.commit()\n",
    "        \n",
    "def insert_image(app, db, project_id, name, path, height, width, dz_tilesize, embedding_coord, group_id, split):\n",
    "    with app.app_context():\n",
    "        image = Image(project_id=project_id,\n",
    "                      name=name,\n",
    "                      path=path,\n",
    "                      height=height,\n",
    "                      width=width,\n",
    "                      dz_tilesize=dz_tilesize,\n",
    "                      embedding_coord=embedding_coord,\n",
    "                      group_id=group_id,\n",
    "                      split=split)\n",
    "        db.session.add(image)\n",
    "        db.session.commit()\n",
    "\n",
    "def insert_image_by_path(app, db, project_id, full_path):\n",
    "    path = full_path.split(\"quickannotator/\")[1]\n",
    "    slide = large_image.getTileSource(path)\n",
    "    name = os.path.basename(full_path)\n",
    "    \n",
    "    with app.app_context():\n",
    "        image = Image(project_id=project_id,\n",
    "                      name=name,\n",
    "                      path=path,\n",
    "                      height=slide.sizeY,\n",
    "                      width=slide.sizeX,\n",
    "                      dz_tilesize=slide.tileWidth,\n",
    "                      embedding_coord=\"POINT (1 1)\",\n",
    "                      group_id=0,\n",
    "                      split=0\n",
    "                      )\n",
    "        \n",
    "        db.session.add(image)\n",
    "        db.session.commit()\n",
    "    \n",
    "def insert_annotation_class(app, db, project_id, name, color, magnification, patchsize, tilesize, dl_model_objectref):\n",
    "    with app.app_context():\n",
    "        annotation_class = AnnotationClass(project_id=project_id,\n",
    "                                           name=name,\n",
    "                                           color=color,\n",
    "                                           magnification=magnification,\n",
    "                                           patchsize=patchsize,\n",
    "                                           tilesize=tilesize,\n",
    "                                           dl_model_objectref=dl_model_objectref)\n",
    "        db.session.add(annotation_class)\n",
    "        db.session.commit()\n",
    "              \n",
    "def insert_tile(app, db, image_id, annotation_class_id, geom, seen):\n",
    "    with app.app_context():\n",
    "        tile = Tile(image_id=image_id,\n",
    "                    annotation_class_id=annotation_class_id,\n",
    "                    geom=geom,\n",
    "                    seen=seen)\n",
    "        \n",
    "        db.session.add(tile)\n",
    "        db.session.commit()\n",
    "        \n",
    "def insert_tiles(app, db, image_id, annotation_class_id):\n",
    "    image_width, image_height = get_image_dimensions(app, image_id)\n",
    "    \n",
    "    with app.app_context():\n",
    "        tile_size = AnnotationClass.query.filter_by(id=annotation_class_id).first().tilesize\n",
    "    \n",
    "    n_cols = math.ceil(image_width / tile_size)\n",
    "    n_rows = math.ceil(image_height / tile_size)\n",
    "    \n",
    "    tiles = []\n",
    "    for i in range(n_rows):\n",
    "        for j in range(n_cols):\n",
    "            t = Tile(image_id=image_id,\n",
    "                     annotation_class_id=annotation_class_id,\n",
    "                     geom=f\"POLYGON(({j*tile_size} {i*tile_size}, {j*tile_size} {(i+1)*tile_size}, {(j+1)*tile_size} {(i+1)*tile_size}, {(j+1)*tile_size} {i*tile_size}, {j*tile_size} {i*tile_size}))\",\n",
    "                     seen=2\n",
    "                     )\n",
    "            tiles.append(t)\n",
    "    with app.app_context():\n",
    "        db.session.add_all(tiles)\n",
    "        db.session.commit()\n",
    "        \n",
    "\n",
    "def annotations_within_bbox(app, db, table, x1, y1, x2, y2):\n",
    "    envelope = func.BuildMbr(x1, y1, x2, y2)\n",
    "    # Right now we are selecting by centroid and not polygon.\n",
    "    with app.app_context():\n",
    "        stmt = table.select().where(func.ST_Intersects(table.c.centroid, envelope))\n",
    "        result = db.session.execute(stmt).fetchall()\n",
    "        \n",
    "    return result\n",
    "  \n",
    "def get_image_dimensions(app, image_id):\n",
    "    with app.app_context():\n",
    "        image = Image.query.filter_by(id=image_id).first()\n",
    "        return image.width, image.height\n",
    "        \n",
    "def create_annotation_table(db, image_id, annotation_class_id, gtpred):\n",
    "    table_name = f\"{image_id}_{annotation_class_id}_{gtpred}_annotation\"\n",
    "    table = Annotation.__table__.to_metadata(db.metadata, name=table_name)\n",
    "    db.metadata.create_all(bind=db.engine, tables=[table])\n",
    "            \n",
    "def generate_random_polygon(max_area=10, centroid=(0, 0)):\n",
    "    num_points = random.randint(10, 20)  # Polygons need at least 3 points\n",
    "\n",
    "    # Generate points in polar coordinates\n",
    "    radii = np.sqrt(np.random.uniform(0, 1, num_points))  # Square root ensures uniform distribution\n",
    "    angles = np.linspace(0, 2 * np.pi, num_points, endpoint=False)\n",
    "\n",
    "    # Convert polar coordinates to Cartesian coordinates\n",
    "    points = [(r * np.cos(a), r * np.sin(a)) for r, a in zip(radii, angles)]\n",
    "\n",
    "    # Sort points to form a simple polygon\n",
    "    sorted_points = sorted(points, key=lambda p: np.arctan2(p[1], p[0]))\n",
    "\n",
    "    # Create a Polygon and scale its area\n",
    "    polygon = Polygon(sorted_points)\n",
    "\n",
    "    # Calculate scaling factor\n",
    "    current_area = polygon.area\n",
    "    if current_area > 0:\n",
    "        scaling_factor = np.sqrt(max_area / current_area)\n",
    "        scaled_points = [(x * scaling_factor, y * scaling_factor) for x, y in sorted_points]\n",
    "        polygon = Polygon(scaled_points)\n",
    "\n",
    "    polygon = translate(polygon, xoff=centroid[0], yoff=centroid[1])\n",
    "\n",
    "    return polygon\n",
    "    \n",
    "def generate_annotations(image_width, image_height, n_polygons):\n",
    "    annotations = []\n",
    "    for i in range(n_polygons):\n",
    "        c = Point(np.random.randint(image_width), np.random.randint(image_height))\n",
    "        \n",
    "        poly: Polygon = generate_random_polygon(max_area=10000, centroid=(c.x, c.y))\n",
    "        d = {\n",
    "            \"centroid\": poly.centroid.wkt,  # Adding SRID=0 for pixel-based coordinates\n",
    "            \"area\": poly.area,  # The area of the polygon\n",
    "            \"polygon\": poly.wkt,  # Adding SRID=0 for the polygon\n",
    "            \"custom_metrics\": json.dumps({\"iou\": 0.5})  # Convert custom_metrics to a JSON string\n",
    "        }\n",
    "        annotations.append(d)\n",
    "        \n",
    "    return annotations\n",
    "\n",
    "def extract_annotations_from_geojson_file(filepath):\n",
    "    path = filepath.split(\"quickannotator/\")[1]\n",
    "    with open(path, 'r') as file:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        data = json.load(file)\n",
    "    \n",
    "    annotations = []\n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "        shapely_geometry = shape(d['geometry'])\n",
    "        annotation = {\n",
    "            \"centroid\": shapely_geometry.centroid.wkt,\n",
    "            \"area\": shapely_geometry.area,\n",
    "            \"polygon\": shapely_geometry.wkt,\n",
    "            \"custom_metrics\": json.dumps({\"iou\": 0.5}) \n",
    "        }\n",
    "        \n",
    "        annotations.append(annotation)\n",
    "        \n",
    "    return annotations\n",
    "\n",
    "        \n",
    "def insert_existing_annotations(app, db, image_id, annotation_class_id, gtpred, filepath):\n",
    "    path = filepath.split(\"quickannotator/\")[1]\n",
    "    with open(path, 'r') as file:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        data = json.load(file)\n",
    "    all_anno = []\n",
    "    \n",
    "    table_name = f\"{image_id}_{annotation_class_id}_{gtpred}_annotation\"\n",
    "    \n",
    "    \n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "        if d['properties']['classification']['name'] == 'tubule':\n",
    "            shapely_geometry = shape(d['geometry'])\n",
    "            annotation = {\n",
    "                \"centroid\": shapely_geometry.centroid.wkt,\n",
    "                \"area\": shapely_geometry.area,\n",
    "                \"polygon\": shapely_geometry.wkt,\n",
    "                \"custom_metrics\": json.dumps({\"iou\": 0.5}) \n",
    "            }\n",
    "            \n",
    "            all_anno.append(annotation)\n",
    "        if len(all_anno)==1_000:\n",
    "            with app.app_context():\n",
    "                table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "                stmt = insert(table).values(all_anno)\n",
    "                db.session.execute(stmt)\n",
    "                db.session.commit()\n",
    "            all_anno = []\n",
    "    \n",
    "    # commit any remaining annotations\n",
    "    with app.app_context():\n",
    "        table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "        stmt = insert(table).values(all_anno)\n",
    "        db.session.execute(stmt)\n",
    "        db.session.commit()\n",
    "        \n",
    "def insert_generated_annotations(app, db, image_id, annotation_class_id, gtpred, n):\n",
    "    all_anno = []\n",
    "    \n",
    "    table_name = f\"{image_id}_{annotation_class_id}_{gtpred}_annotation\"\n",
    "    with app.app_context():\n",
    "        image = db.session.query(Image).filter_by(id=image_id).first()\n",
    "        table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "        for i, d in enumerate(tqdm(range(n))):\n",
    "            annotation = generate_annotations(image.width, image.height, 1)[0]\n",
    "            all_anno.append(annotation)\n",
    "            if len(all_anno)==1_000:\n",
    "                stmt = insert(table).values(all_anno)\n",
    "                db.session.execute(stmt)\n",
    "                db.session.commit()\n",
    "                all_anno = []\n",
    "    \n",
    "    # commit any remaining annotations\n",
    "    with app.app_context():\n",
    "        table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "        stmt = insert(table).values(all_anno)\n",
    "        db.session.execute(stmt)\n",
    "        db.session.commit()\n",
    "            \n",
    "def insert_qupath_geojson_file(app, db, image_id, annotation_class_id, gtpred, filepath):\n",
    "    '''\n",
    "    This is expected to be a geojson feature collection file, with each polygon being a feature.\n",
    "    \n",
    "    '''\n",
    "    path = filepath.split(\"quickannotator/\")[1]\n",
    "    with open(path, 'r') as file:\n",
    "        # Load the JSON data into a Python dictionary\n",
    "        data = json.load(file)[\"features\"]\n",
    "    all_anno = []\n",
    "    \n",
    "    table_name = f\"{image_id}_{annotation_class_id}_{gtpred}_annotation\"\n",
    "    \n",
    "    \n",
    "    for i, d in enumerate(tqdm(data)):\n",
    "\n",
    "        shapely_geometry = shape(d['geometry'])\n",
    "        annotation = {\n",
    "            \"centroid\": shapely_geometry.centroid.wkt,\n",
    "            \"area\": shapely_geometry.area,\n",
    "            \"polygon\": shapely_geometry.wkt,\n",
    "            \"custom_metrics\": json.dumps({\"iou\": 0.5}) \n",
    "        }\n",
    "        \n",
    "        all_anno.append(annotation)\n",
    "        \n",
    "        if len(all_anno)==1_000:\n",
    "            with app.app_context():\n",
    "                table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "                stmt = insert(table).values(all_anno)\n",
    "                db.session.execute(stmt)\n",
    "                db.session.commit()\n",
    "            all_anno = []\n",
    "    \n",
    "    # commit any remaining annotations\n",
    "    with app.app_context():\n",
    "        table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "        stmt = insert(table).values(all_anno)\n",
    "        db.session.execute(stmt)\n",
    "        db.session.commit()\n"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:35:08.299209Z",
     "start_time": "2024-11-08T14:35:07.667888Z"
    }
   },
   "cell_type": "code",
   "source": [
    "models = [Project, Image, AnnotationClass, Notification, Tile, Setting]\n",
    "with app.app_context():\n",
    "    db.metadata.create_all(bind=db.engine, tables=[item.__table__ for item in models])\n",
    "    create_annotation_table(db, 1, 1, \"gt\")\n",
    "    create_annotation_table(db, 1, 2, \"gt\")\n",
    "    create_annotation_table(db, 2, 1, \"gt\")\n",
    "    create_annotation_table(db, 2, 2, \"gt\")\n",
    "    "
   ],
   "id": "6c470570e9995f60",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:41:40.317697Z",
     "start_time": "2024-11-08T14:35:08.312880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "insert_project(app, db, \n",
    "               name=\"example_project\", \n",
    "               description=\"test\", \n",
    "               is_dataset_large=False)\n",
    "insert_image_by_path(app, db,\n",
    "                     project_id=1,\n",
    "                     full_path=\"quickannotator/data/test_ndpi/13_266069_040_003 L02 PAS.ndpi\"\n",
    "                     )\n",
    "\n",
    "insert_image_by_path(app, db,\n",
    "                     project_id=1,\n",
    "                     full_path=\"quickannotator/data/test_ndpi/TCGA-23-2072-01Z-00-DX1.478243FF-BFF0-48A4-ADEA-DE789331A50E.svs\")\n",
    "\n",
    "insert_annotation_class(app, db,\n",
    "                        project_id=None,\n",
    "                        name=\"Tissue Mask\",\n",
    "                        color=\"black\",\n",
    "                        magnification=None,\n",
    "                        patchsize=None,\n",
    "                        tilesize=None,\n",
    "                        dl_model_objectref=None)\n",
    "\n",
    "insert_annotation_class(app, db,\n",
    "                        project_id=1,\n",
    "                        name=\"Tubule\",\n",
    "                        color=\"red\",\n",
    "                        magnification=10,\n",
    "                        patchsize=256,\n",
    "                        tilesize=2048,\n",
    "                        dl_model_objectref=None)\n",
    "\n",
    "insert_tiles(app, db, image_id=1, annotation_class_id=2)\n",
    "\n",
    "insert_tiles(app, db, image_id=2, annotation_class_id=2)\n",
    "\n",
    "insert_generated_annotations(app, db, image_id=2, annotation_class_id=2, gtpred=\"gt\", n=1_000_000)"
   ],
   "id": "71c1d6c415fb4a5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000000/1000000 [06:31<00:00, 2553.67it/s]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "c41c4ce245fc68d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:41:54.012654Z",
     "start_time": "2024-11-08T14:41:40.323315Z"
    }
   },
   "source": [
    "\n",
    "insert_existing_annotations(app, db,\n",
    "                            image_id=1,\n",
    "                            annotation_class_id=2,\n",
    "                            gtpred=\"gt\",\n",
    "                            filepath='quickannotator/data/test_ndpi/13_266069_040_003 L02 PAS.json'\n",
    "                            )"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88605/88605 [00:04<00:00, 17803.77it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:41:54.035138Z",
     "start_time": "2024-11-08T14:41:54.017313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "insert_qupath_geojson_file(app, db,\n",
    "                            image_id=1,\n",
    "                            annotation_class_id=1,\n",
    "                            gtpred='gt',\n",
    "                            filepath='quickannotator/data/test_ndpi/13_266069_040_003 L02 PAS_tissue_mask.geojson')\n",
    "\n",
    "insert_qupath_geojson_file(app, db, \n",
    "                           image_id=2,\n",
    "                           annotation_class_id=1,\n",
    "                           gtpred='gt',\n",
    "                           filepath='quickannotator/data/test_ndpi/TCGA-23-2072-01Z-00-DX1.478243FF-BFF0-48A4-ADEA-DE789331A50E_tissue_mask.geojson')\n"
   ],
   "id": "fe49e7aa",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 1042.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 5966.29it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "e2187ac88d5fd4b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-08T14:42:48.573948Z",
     "start_time": "2024-11-08T14:42:46.274069Z"
    }
   },
   "source": [
    "with app.app_context():\n",
    "    table_name = '2_2_gt_annotation'\n",
    "    table = Table(table_name, db.metadata, autoload_with=db.engine)\n",
    "    %timeit anns = annotations_within_bbox(app, db, table, 10000,10000,10150,10150)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 ms ± 22.4 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "219c44e478f7e63d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
